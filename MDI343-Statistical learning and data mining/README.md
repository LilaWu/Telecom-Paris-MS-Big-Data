# MDI343-Statistical learning and data mining

Many modern applications such as web data, genomics, finance, e-marketing need to hangling and processing very large data. The discipline taht develops and studies concrete methods for modeling this type of data is called statistical machine learning. Ultimately, it is about producting prediction and decision support tools dedicated to a specific application. The appearance of very powerful algorithms for the calssification of large-scale data, such as boosting or Support Vector Machines in the mid-90s, gradually replaced the traditional statitics which relied largely on the manual preprocessing.

Based on theory popularized by Vapnik (The Natural of Statistical Learning, 1995), a new research stram was born: it links the mathematical and computer communities and mobilizes a growing number of young researchers turned towards big data analysis.

In this course, I got deeper understanding of this domain, it's fondations, the problems it addresses (supervised and unsupervised problems), and the most recent methods that are currently being studied (SVM, Boosting, Lasso, etc.).
The interest of these concepts and techniques presented below will be illustrated through concerte applications, like textual data, images, audio signals, genomic data, industrial problems, etc.

1. General introduction to the prediction problems: classification, regression, anomaly detection, ranking and density estimation. The case of classification: statistical model, performance measure, optimality. 
2. Elements of learning theory. The case of classification: statistical aspects, principle of minimization of empirical risk. Complement: Exponential inequalities, deviation and concentration. 
3. Control of the complexity in the case of classification. Metric Entropy vs. combinatorial measures. Standard classification methods: linear classifiers, decision trees, nuclei, neural networks 
4. State-of-the-art classification methods: boosting, SVM, bagging. Towards pragmatic strategies: minimization of the convexified risk, statistical aspects. 
5. Methods of regularization for the control of the complexity. 
6. Regression. Penalized linear regression methods vs. Lasso. Performance vs. “Sparsity”.
7. Detection of anomalies and Ranking. The ROC curve and the AUC: performance criteria for discrimination. 
8. Unsupervised problems. Nonparametric density estimation. Clustering. Latent variable models (independent component analysis, kernel PCA, hidden Markov models). Algorithmic aspects (EM algorithm and variants)
